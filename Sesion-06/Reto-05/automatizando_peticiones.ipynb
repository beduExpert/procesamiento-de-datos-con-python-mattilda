{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reto 5: Automatizando peticiones\n",
    "\n",
    "### 1. Objetivos:\n",
    "    - Automatizar la petición de datos a la API de la NASA por fechas.\n",
    " \n",
    "---\n",
    "    \n",
    "### 2. Desarrollo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Automatizando peticiones\n",
    "\n",
    "En el primer Reto realizaste una petición a la API de la NASA para pedir 5 datos de la hoja #100. Ahora, vamos a automatizar el proceso de realizar peticiones a la API para obtener una cantidad bastante mayor de datos.\n",
    "\n",
    "Vamos a obtener ahora los datos por fechas, así que tendrás que ir a la página de la [api de la NASA](https://api.nasa.gov/), para revisar cómo es posible realizar peticiones por fecha. Queremos obtener los **dos primeros meses (Enero y Febrero) del año 1995**. Observa que la API sólo permite peticiones por fecha en rangos de 7 días.\n",
    "\n",
    "Tu reto tiene los siguientes pasos:\n",
    "\n",
    "1. Revisa la documentación de la API de la NASA para entender cómo realizar peticiones por fecha.\n",
    "2. Realiza una primera petición de prueba para entender el formato de los datos que obtienes de regreso (cómo extraemos los datos que necesitamos y qué estructura tienen).\n",
    "2. Escribe el código necesario para automatizar las peticiones a la API y obtener los meses de Enero y Febrero del año 1995.\n",
    "3. Almacena los datos de cada petición y luego usa esos datos para crear `DataFrames`.\n",
    "4. Concatena verticalmente tus `DataFrames` para obtener un `DataFrame` final que contenga todos los datos de tus peticiones. Cada fila tiene que corresponder a un objeto espacial.\n",
    "5. Guarda tu `DataFrame` con el nombre de `near_earth_objects-january_february_1995-raw.csv`.\n",
    "\n",
    "> **Nota**: En este momento no te preocupes por explorar o limpiar tu dataset. Eso lo haremos en la siguiente sesión. Lo que sí tienes que asegurarte es de normalizar tus datos antes de convertirlos en `DataFrame`.\n",
    "\n",
    "¡Mucha suerte!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data_science)",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
